# afl-fuzz白皮书

本文提供了 American Fuzzy Lop 的核心功能的快速概述。有关一般使用说明，请参见README文件；有关AFL背后的动机和设计目标的讨论，请参见historical_notes.txt文件。

## 0）设计原则

American Fuzzy Lop 尽力不着重于任何单一的操作原则，也不是任何特定理论的概念验证。该工具可以被认为是一系列经过实践测试、发现效果惊人并以我当时所能想到的最简单、最可靠的方式实现的黑客技巧的集合。

许多结果特性都是由于轻量级的仪器化工具的可用性而成为可能的，但这种机制仅应被视为达到目标的手段。唯一真正的统治原则是速度、可靠性和易用性。

## 1）覆盖率计算

注入到编译程序中的仪器化工具可以捕获分支（边缘）覆盖率，以及粗略的分支转移命中计数。在分支点注入的代码本质上等同于：

```
cur_location = <COMPILE_TIME_RANDOM>; 
shared_mem[cur_location ^ prev_location]++; 
prev_location = cur_location >> 1;
```

cur_location 值是随机生成的，以简化链接复杂项目的过程并保持 XOR 输出均匀分布。

shared_mem\[\] 数组是由调用方传递给仪器化二进制文件的 64 kB SHM 区域。输出映射中设置的每个字节都可以视为对仪器化代码中特定的 (branch_src, branch_dst) 元组的命中。

地图的大小被选择为与几乎所有预期目标的2k到10k可发现分支点相碰撞的时候是零散的：

| Branch cnt | Colliding tuples | Example targets |
| ---------- | ---------------- | --------------- |
| 1,000      | 0.75%            | giflib, lzo     |
| 2,000      | 1.5%             | zlib, tar, xz   |
| 5,000      | 3.5%             | libpng, libwebp |
| 10,000     | 7%               | libxml          |
| 20,000     | 14%              | sqlite          |
| 50,000     | 30%              | -               |

同时，其大小足够小，使得接收端能够在微秒内分析地图，并轻松适合L2缓存中。

这种覆盖提供了比简单块覆盖更多的程序执行路径信息。特别是，它可以轻松地区分以下执行跟踪：

```
A -> B -> C -> D -> E (元组：AB、BC、CD和DE) 
A -> B -> D -> C -> E (元组：AB、BD、DC和CE)
```

这对于发现潜在代码中的微妙故障条件非常有帮助，因为安全漏洞更经常与意外或不正确的状态转换相关，而不是仅仅到达新的基本块。

此前在本节中显示的伪代码中最后一行移位操作的原因是为了保留元组的方向性(否则，A ^ B将无法区分B ^ A)，并保留紧密循环的身份(否则，A ^ A将明显等于B ^ B)。

英特尔CPU上缺少简单的饱和算术操作码意味着命中计数器有时会回绕为零。由于这是一个相当不太可能和局部的事件，因此被视为可以接受的性能折衷。

## 2）检测新行为

模糊测试器包含先前执行中看到的元组的全局映射；这些数据可以快速与单个跟踪进行比较，并只需几个 dword 或 qword 宽指令和一个简单的循环即可更新。

当变异输入产生包含新元组的执行跟踪时，相应的输入文件将被保留并路由到以后进行额外处理（见第3节）。不触发执行跟踪中的新局部规模状态转换（即不生成新元组）的输入将被丢弃，即使它们的整体控制流序列是唯一的。

这种方法允许对程序状态进行非常细粒度和长期的探索，而无需执行任何计算密集型和易碎的复杂执行跟踪的全局比较，并避免路径爆炸的困扰。

为了说明算法的特性，请考虑下面显示的第二个跟踪，由于存在新的元组 (CA、AE)，因此将被认为具有实质上的新内容：

```
#1：A -> B -> C -> D -> E 
#2：A -> B -> C -> A -> E
```

同时，使用 #2 进行处理时，以下模式将不会被视为唯一，尽管其整体执行路径明显不同：

```
#3: A -> B -> C -> A -> B -> C -> A -> B -> C -> D -> E
```

除了检测新元组外，模糊测试器还考虑粗略的元组命中计数。这些被分为几个bucket：

```
1、2、3、4-7、8-15、16-31、32-127、128+
```

在某种程度上，bucket 的数量是一种实现特性：它允许将由仪器化生成的8比特计数器就地映射到供模糊测试器可执行文件依赖的8个位置的位图中，以跟踪每个元组的已看到执行计数。

在单个 bucket 范围内的更改将被忽略；从一个 bucket 到另一个 bucket 的转换被标记为程序控制流的有趣变化，并被路由到下面的进化过程中。

命中计数行为提供了一种区分潜在有趣的控制流变化的方式，例如当通常只有一次触发时，代码块被执行了两次。同时，它对经验上不那么显著的更改（例如循环从47个周期变为48个周期）比较不敏感。这些计数器也为密集跟踪映射中的元组冲突提供了某种程度的“偶然”免疫。

通过内存和执行时间限制，执行受到相当严格的监管；默认情况下，超时设置为5倍初始校准执行速度，四舍五入到20毫秒。攻击性的超时旨在防止模糊测试器性能的剧烈下降，因为进入陷阱时，覆盖率只提高了1%，而速度变慢了100倍；实用性的考虑下不采用，并希望模糊测试器能够找到更便宜的方法来达到相同的代码。经验测试强烈建议不要付出更大代价的更宽松时间限制。

## 3）输入队列的进化

生成新状态转换的变异测试用例将添加到输入队列并用作未来模糊测试轮次的起点。它们是现有发现的补充，但不会自动替换它们。

与更贪心的遗传算法相比，这种方法允许工具逐步探索底层数据格式的各种不同和可能相互不兼容的特征，如下图所示：

![图片](http://lcamtuf.coredump.cx/afl/afl_gzip.png)

这个算法的几个实际例子在这里讨论：
[http://lcamtuf.blogspot.com/2014/11/pulling-jpegs-out-of-thin-air.html](http://lcamtuf.blogspot.com/2014/11/pulling-jpegs-out-of-thin-air.html) [http://lcamtuf.blogspot.com/2014/11/afl-fuzz-nobody-expects-cdata-sections.html](http://lcamtuf.blogspot.com/2014/11/afl-fuzz-nobody-expects-cdata-sections.html)

这个过程产生的合成语料库本质上是一个紧凑的“做了一些新事情”的输入文件集合，并可用于为其他测试流程播种(例如手动压力测试资源密集型桌面应用程序)。

使用这种方法，大多数目标的队列增长到1k到10k条目之间；其中大约10-30%是由于发现新元组，其余部分与命中计数的更改相关。

以下表格比较了使用几种不同方法进行引导模糊测试时，发现文件语法和探索程序状态的相对能力。仪器化目标是使用 `-O3` 编译的 GNU patch 2.7.3，并使用虚拟文本文件进行播种；会话包括对输入队列的单次通过，采用 afl-fuzz：

| Fuzzer guidance strategy used | Blocks reached | Edges reached | Edge hit cnt var | Highest-coverage test case generated |
| ----------------------------- | -------------- | ------------- | ---------------- | ------------------------------------ |
| (Initial file)                | 156            | 163           | 1.00             | (none)                               |
| Blind fuzzing S               | 182            | 205           | 2.23             | First 2 B of RCS diff                |
| Blind fuzzing L               | 228            | 265           | 2.23             | First 4 B of -c mode diff            |
| Block coverage                | 855            | 1,130         | 1.57             | Almost-valid RCS diff                |
| Edge coverage                 | 1,452          | 2,070         | 2.18             | One-chunk -c mode diff               |
| AFL model                     | 1,765          | 2,597         | 4.99             | Four-chunk -c mode diff              |

第一条 blind fuzzing ("S") 表示只执行一轮测试；第二组数据（“L”）显示模糊测试器在循环中运行，执行的次数与插桩运行的次数相当，这需要更多时间来完全处理不断增长的队列。

在另一个单独的实验中，通过修改模糊测试器以编译掉所有随机模糊测试阶段，并只保留一系列基本的顺序操作，比如翻转位，也得到了类似的结果。由于此模式无法改变输入文件的大小，因此会话从一个有效的统一 diff 开始。

| Queue extension strategy used | Blocks reached | Edges reached | Edge hit cnt var | Number of unique |
| ----------------------------- | -------------- | ------------- | ---------------- | ---------------- |
| (Initial file)                | 624            | 717           | 1.00             | -                |
| Blind fuzzing                 | 1,101          | 1,409         | 1.60             | 0                |
| Block coverage                | 1,255          | 1,649         | 1.48             | 0                |
| Edge coverage                 | 1,259          | 1,734         | 1.72             | 0                |
| AFL model                     | 1,452          | 2,040         | 3.16             | 1                |

正如之前所述，一些基于遗传算法的模糊测试方法依赖于维护单个测试用例并通过进化算法来最大化测试覆盖率。然而，在上述测试中，这种“贪心”方法似乎并没有比盲目模糊测试策略带来实质性的优势。

## 4）精简语料库

上面概述的渐进状态探索方法意味着后期合成的一些测试用例可能具有其祖先所提供的边缘覆盖范围的严格子集。

为了优化模糊测试效果，AFL会定期使用快速算法重新评估队列，选择仅覆盖到目前为止每个元组的更小的测试用例子集，并且这些测试用例的特性使它们对工具特别有利。

该算法通过为每个队列条目分配与执行延迟和文件大小成比例的分数来工作，然后为每个元组选择最低分数的候选项。

然后，序列化地处理这些元组：
1.  找到尚未在临时工作集中的下一个元组，
2.  定位此元组的获胜队列条目，
3.  注册该条目跟踪中存在的所有元组到工作集中，
4.  如果集合中有任何缺失的元组，请转到#1。

生成的“受青睐”的条目语料库通常比起始数据集小5-10倍。非受青睐的条目不会被丢弃，但在队列中遇到时，将以不同的概率被跳过：
-   如果队列中存在尚未进行模糊测试的新的受青睐个体，则99％的非受青睐个体将被跳过以获取受青睐的个体。
-   如果没有新的受青睐个体：
    -   如果当前的非受青睐个体之前已进行过模糊测试，则有95％的几率会被跳过。
    -   如果它尚未经过任何模糊测试轮次，则跳过的几率降至75％。

基于经验测试，它提供了队列循环速度和测试用例多样性之间的合理平衡。

可以使用 afl-cmin 更为复杂但慢得多的精简工具对输入或输出语料库进行精简。该工具会永久丢弃冗余条目，并生成适合用于 afl-fuzz 或外部工具的较小语料库。

## 5）修建输入文件

文件大小对模糊测试的性能有巨大影响，因为大文件会使目标二进制程序变慢，并且它们减少了突变可能触及的重要格式控制结构的可能性，而不是冗余数据块。这在 perf_tips.txt 中详细讨论。

除了用户提供低质量的起始语料库的可能性外，某些类型的突变会逐步增加生成文件的大小，因此重要的是要抵消这种趋势。

幸运的是，仪器化反馈（instrumentation feedback）提供了一种简单的方法来自动修剪输入文件，同时确保对文件进行的更改不会影响执行路径。

afl-fuzz 中内置的修剪器尝试顺序地删除具有可变长度和步进的数据块；任何不影响跟踪映射的校验和的删除都会被提交到磁盘。修剪器并不旨在特别彻底；相反，它尝试在精度和用于进程的 execve() 调用数量之间取得平衡，选择匹配的块大小和步进。每个文件的平均收益约为 5-20％。

独立的 afl-tmin 工具使用更详尽的迭代算法，并且还尝试对修剪后的文件执行字母规范化。afl-tmin 的操作如下。

首先，该工具会自动选择操作模式。如果初始输入导致目标二进制程序崩溃，则 afl-tmin 将在非仪器化模式下运行，简单地保留任何产生更简单的文件但仍会使目标崩溃的微调。如果目标没有崩溃，则该工具使用仪器化模式，并仅保留产生完全相同执行路径的微调。

实际最小化算法如下：
1. 尝试用大步长零大块数据。 根据经验，这样做可以通过预先终止后来更精细的努力来减少 execs 的数量。
2. 按照二进制搜索方式进行块删除，大小和步长递减。
3. 通过计算唯一字符并尝试以零值批量替换它们来执行字母规范化。
4. 作为最后一步，对非零字节执行逐字节规范化。

与用于表示 0x00 字节的空字节不同，afl-tmin 使用 ASCII 数字 '0' 进行零值操作。这样做是因为这种修改不太可能干扰文本解析，因此更有可能成功地最小化文本文件。

这里使用的算法比学术研究中提出的其他测试用例最小化方法要简单得多，但需要更少的执行，并趋向于在大多数现实世界应用中产生可比较的结果。

## 6）模糊测试策略

插桩提供的反馈使得理解各种模糊测试策略的价值并优化其参数更简单，以便它们在各种文件类型上同样有效变得容易。afl-fuzz 使用的策略通常是格式无关的，并在这里进行了更详细的讨论：[http://lcamtuf.blogspot.com/2014/08/binary-fuzzing-strategies-what-works.html](http://lcamtuf.blogspot.com/2014/08/binary-fuzzing-strategies-what-works.html)

值得注意的是，尤其是在早期阶段，afl-fuzz 大部分工作实际上是高度确定性的，并且只在后期进展到随机堆叠修改和测试用例拼接。确定性策略包括：
- 带有不同长度和步进的顺序位翻转，
- 小整数的顺序加减法，
- 已知有趣整数（0、1、INT_MAX 等）的顺序插入，

采用确定性步骤的目的与它们倾向于产生紧凑的测试用例和非崩溃输入之间的小差异有关。

确定性模糊测试完成后，非确定性步骤包括堆叠的位翻转、插入、删除、算术和不同测试用例的拼接。

所有这些策略的相对收益和 execve() 成本已经得到了调查，并在上述博客文章中进行了讨论。

由于 historical_notes.txt 中所讨论的原因（主要是性能、简单性和可靠性），AFL 通常不会尝试推断特定变异和程序状态之间的关系；模糊测试步骤名义上是盲目的，仅由输入队列的进化设计指导。

即便如此，有一个（微不足道的）例外：当新的队列条目经过初始的确定性模糊测试步骤时，如果观察到对文件中某些区域的微调对执行路径的校验和没有影响，则可能将它们排除在确定性模糊测试的其余阶段之外，而直接进行随机微调。特别是对于冗长且易于人类阅读的数据格式，这可以在不显著降低覆盖率的情况下将 execs 的数量减少约 10-40%。在极端情况下，例如通常块对齐的 tar 存档，收益可能高达 90％。

由于底层的“效应器映射”每个队列条目都是本地的，并且仅在不改变底层文件的大小或一般布局的确定性阶段中保持有效，因此该机制似乎非常可靠并且被证明易于实现。

## 7）字典

插桩提供的反馈使得自动识别某些类型输入文件中的语法标记并检测预定义或自动检测的某些字典术语组合构成测试解析器的有效语法变得容易。

关于这些功能在 afl-fuzz 中如何实现的讨论可以在这里找到：[http://lcamtuf.blogspot.com/2015/01/afl-fuzz-making-up-grammar-with.html](http://lcamtuf.blogspot.com/2015/01/afl-fuzz-making-up-grammar-with.html)

简而言之，当基本的、通常容易获取的语法标记以纯随机的方式组合在一起时，插桩和队列的进化设计共同提供了一种反馈机制，以区分无意义的突变和触发仪器化代码中新行为的突变，并逐步在此发现的基础上构建更复杂的语法。

已经证明字典可以使 fuzzer 快速重建高度冗长和复杂的语言（如 JavaScript、SQL 或 XML）的语法；博客文章中提供了生成的 SQL 语句的几个示例。

有趣的是，AFL 仪器化还允许 fuzzer 自动隔离已经存在于输入文件中的语法标记。它可以通过查找字节运行来做到这一点，即当这些字节被翻转时，会对程序的执行路径产生一致的变化；这暗示了一个内在的原子比较与代码中预定义值的比较。fuzzer 依赖于这个信号来构建紧凑的“自动字典”，然后与其他模糊测试策略一起使用。

## 8）crash去重

对于任何一个称职的模糊测试工具来说，去重崩溃是一个更为重要的问题。许多朴素的方法都会遇到问题；特别是，如果故障发生在公共库函数中（比如 strcmp、strcpy），那么仅查看错误地址可能会导致完全不相关的问题被聚集在一起；而对调用堆栈回溯进行校验和运算则可能导致崩溃计数极度膨胀，如果通过多个不同的、可能是递归的代码路径可以达到故障。

afl-fuzz 中实现的解决方案认为，如果满足以下两个条件之一，则崩溃是唯一的：
- 崩溃跟踪包括先前崩溃中未见过的元组，
- 崩溃跟踪缺少以前所有故障中始终存在的元组。

该方法在早期容易受到某些路径计数的影响，但表现出非常强的自我限制效果，类似于 afl-fuzz 的执行路径分析逻辑，这是其基石。

## 9）crash研究

许多类型的crash的可利用性可能是模糊的；afl-fuzz 通过提供一个崩溃探索模式来解决这个问题，在该模式下，已知故障测试用例以与 fuzzer 的正常操作非常相似的方式进行模糊测试，但有一个约束条件，使得任何非崩溃变异都被丢弃。

关于这种方法的价值的详细讨论可以在这里找到：
[http://lcamtuf.blogspot.com/2014/11/afl-fuzz-crash-exploration-mode.html](http://lcamtuf.blogspot.com/2014/11/afl-fuzz-crash-exploration-mode.html)

该方法使用仪器化反馈来探索崩溃程序的状态，以克服不确定的故障条件，然后隔离新发现的输入以供人工审查。

关于崩溃的问题，值得注意的是，与正常队列条目不同，崩溃输入并没有被修剪。它们被保留为发现时的确切样子，以便更容易与队列中的父级非崩溃条目进行比较。即便如此，afl-tmin 也可以随意地将它们收缩。

## 10）fork server

为了提高性能，afl-fuzz使用“fork server”。在这个过程中，被模糊处理的进程只通过一次execve()、链接和libc初始化，然后通过利用写时复制从已停止的进程镜像克隆。其实现在这里有更详细的描述：
[http://lcamtuf.blogspot.com/2014/10/fuzzing-binaries-without-execve.html](http://lcamtuf.blogspot.com/2014/10/fuzzing-binaries-without-execve.html)

fork server 是注入的插桩的一个重要方面，只需在第一个插装的函数处停止等待来自afl-fuzz的命令即可。

对于需要快速fuzz的目标， fork server可以提供相当大的性能提升，通常在1.5倍到2倍之间。也可以：
-   在手动（“延迟”）模式下使用fork服务器，跳过较大、用户选择的初始化代码块。这需要非常少量的针对性程序代码更改，并且对于某些目标，可以产生10倍以上的性能提升。
-   启用“持久化”模式，其中一个进程用于尝试多个输入，从而极大地限制了重复的fork()调用的开销。这通常需要对针对性程序进行一些代码更改，但可以将快速目标的性能提高5倍或更多——近似于进程内模糊处理作业的好处，同时仍保持模糊器进程和目标二进制文件之间非常强大的隔离性。

## 11）并行

并行机制依赖于定期检查由在其他CPU核心或远程计算机上独立运行的实例产生的队列，然后有选择地拉入在本地试验时产生的尚未被当前模糊器观察到的行为的测试用例。

这使得模糊器设置极其灵活，包括针对共同数据格式的不同解析器运行同步实例，通常具有协同效应。

有关此设计的更多信息见 parallel_fuzzing.txt。

## 12）仅二进制插桩

黑盒、仅二进制目标的插桩是通过在“用户仿真”模式下使用一个单独构建的QEMU版本来完成的。这也允许执行跨体系结构的代码，比如在x86上运行ARM二进制文件。

QEMU使用基本块作为翻译单元；插桩是在此之上实现的，并使用与编译时钩子大致相似的模型：

```
if (block_address > elf_text_start && block_address < elf_text_end) {
	cur_location = (block_address >> 4) ^ (block_address << 8);
	shared_mem[cur_location ^ prev_location]++; 
	prev_location = cur_location >> 1;
}
```

第二行中基于移位和异或的混淆用于掩盖指令对齐的影响。

像QEMU、DynamoRIO和PIN这样的二进制翻译器的启动速度非常慢；为了解决这个问题，QEMU模式利用了类似于编译器插桩代码所使用的fork服务器，有效地产生了已在_start处暂停的已初始化进程的副本。

首次翻译新基本块也会产生相当大的延迟。为了消除这个问题，AFL fork服务器通过提供正在运行的仿真器和父进程之间的通道进行了扩展。该通道用于通知父进程有关任何新遇到的块的地址，并将它们添加到将为未来子进程复制的翻译缓存中。

由于这两个优化，QEMU模式的开销大约是2-5倍，而PIN的开销则超过100倍。

## 13）afl-analyze工具

文件格式分析工具是前面讨论的最小化算法的简单扩展；该工具不尝试删除无操作块，而是执行一系列步进字节翻转，然后注释输入文件中的字节运行。

它使用以下分类方案：
-   “无操作块（No-op blocks）”：位翻转导致控制流不发生明显变化的段。常见的例子可能是注释部分、位图文件中的像素数据等。
-   “表面内容（Superficial content）”：段落中某些但不是全部位翻转会产生一些控制流程变化。例如富文档中的字符串（如XML、RTF）。
-   “关键流（Critical stream）”：一个字节序列，在不同但相关的方式下所有位翻转都会改变控制流。这可能是压缩数据、非原子比较的关键词或魔数值等。
-   “可疑的长度字段（Suspected length field）”：小型的原子整数，以任何方式触摸到时，都会导致对程序控制流的一致更改，暗示失败的长度检查。
-   “可疑的校验和或魔术整数（Suspected cksum or magic int）”：一个整数，类似于长度字段的行为，但其数值使得长度解释不太可能。这暗示了校验和或其他“魔法”整数。
-   “可疑的校验和块（Suspected checksummed block）”：一个长的数据块，其中任何更改总是触发相同的新执行路径。可能是在任何后续解析之前失败校验和或类似完整性检查导致的。
-   “魔数值部分（Magic value section）”：一种通用令牌，其更改会导致前面概述的二进制行为类型，但不符合任何其他标准。可能是原子比较的关键字等。
